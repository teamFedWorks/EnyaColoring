{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3961f3-5e6c-4669-9455-13bd3c7107f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def crop_video_ffmpeg(input_path, output_path, start_crop, end_crop):\n",
    "    ffmpeg_cmd = [\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-ss\", start_crop, \"-to\", end_crop,\n",
    "        \"-i\", input_path,\n",
    "        \"-c\", \"copy\",\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        print(f\"ðŸ”§ Cropping video from {start_crop} to {end_crop}...\")\n",
    "        subprocess.run(ffmpeg_cmd, check=True)\n",
    "        print(f\"âœ‚ï¸ Saved cropped video to: {output_path}\")\n",
    "        return \"Success\", output_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ ffmpeg failed: {e}\")\n",
    "        return \"Error\", f\"FFmpeg crop failed: {e}\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {e}\")\n",
    "        return \"Error\", f\"Unexpected error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a2d98e3-98d9-4128-8400-41744f80b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Cropping video from 00:00:00 to 00:00:44...\n",
      "âœ‚ï¸ Saved cropped video to: input_videos_cropped/cropped_SivasankariSivanandalahariFullVi_20250701035457_2ea8e47d_000_044.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input_videos/SivasankariSivanandalahariFullVi_20250701035457_2ea8e47d.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:05:44.98, start: 0.000000, bitrate: 925 kb/s\n",
      "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 787 kb/s, 50 fps, 50 tbr, 12800 tbn, 100 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Output #0, mp4, to 'input_videos_cropped/cropped_SivasankariSivanandalahariFullVi_20250701035457_2ea8e47d_000_044.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 787 kb/s, 50 fps, 50 tbr, 12800 tbn, 12800 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #0:1 -> #0:1 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame= 2201 fps=0.0 q=-1.0 Lsize=    4482kB time=00:00:43.98 bitrate= 834.8kbits/s speed=5.78e+03x    \n",
      "video:3740kB audio:688kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.233429%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Success',\n",
       " 'input_videos_cropped/cropped_SivasankariSivanandalahariFullVi_20250701035457_2ea8e47d_000_044.mp4')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_video_ffmpeg(\n",
    "    input_path=\"input_videos/SivasankariSivanandalahariFullVi_20250701035457_2ea8e47d.mp4\",\n",
    "    output_path=\"input_videos_cropped/cropped_SivasankariSivanandalahariFullVi_20250701035457_2ea8e47d_000_044.mp4\",\n",
    "    start_crop=\"00:00:00\",  # 1 min 10 sec\n",
    "    end_crop=\"00:00:44\"     # 2 min 45 sec\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0c9520-1d34-418e-9b01-ffbd92566889",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_flag =True\n",
    "upscale_flag =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e96fe-a45b-42c7-a960-812bde6d14f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332ba84f-5f7d-47c1-99ec-26805833bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = 'input_videos/Marilyn_Monroe_test.mp4' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45178cd9-44c8-4aac-b864-c1f7f13c4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_video_path=None\n",
    "faces_upscaled_video_path=None\n",
    "onnx_upscaled_video =None\n",
    "preview_video_path =None\n",
    "preview_upscaled_video =None\n",
    "deoldify_video =None\n",
    "colorized_final_video =None\n",
    "final_video =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38eeb889-98ac-453c-abd9-8460a4a58c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CACHE] Valid restored B&W video found: output_videos_latest/Marilyn_Monroe_test/restore_bw_film__0e4836bf045c/restore_bw_film.mp4\n",
      "Restored video available at: output_videos_latest/Marilyn_Monroe_test/restore_bw_film__0e4836bf045c/restore_bw_film.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "from Utils.main_utils import restore_bw_film_cached\n",
    "\n",
    "restored_video_path = restore_bw_film_cached(input_video_path, input_video_path)\n",
    "\n",
    "print(f\"Restored video available at: {restored_video_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0823f64-18bd-455c-b59b-1a723d926792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 17:02:04.606650: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-29 17:02:04.616007: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751230924.626097     371 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751230924.629184     371 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751230924.637518     371 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751230924.637527     371 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751230924.637528     371 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751230924.637529     371 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-29 17:02:04.640434: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "WARNING:tensorflow:From /tmp/ipykernel_371/1683956900.py:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751230926.399553     371 gpu_device.cc:2019] Created device /device:GPU:0 with 14294 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e61d4b-184e-45c1-9f40-008b3ceb0e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "Torchvision version: 0.20.1+cu121\n",
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d23826-05ce-46c2-acca-5420c1935bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CACHE] Faces upscaled video found: output_videos_latest/Marilyn_Monroe_test/faces_upscale__cad2c27a2d16/faces_upscale.mp4\n",
      "face-enhanced video available at: output_videos_latest/Marilyn_Monroe_test/faces_upscale__cad2c27a2d16/faces_upscale.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "from Utils.main_utils  import upscale_faces_cached\n",
    "\n",
    "# Output from Task 2 (upscaled)\n",
    "input_path = restored_video_path or input_video_path\n",
    "\n",
    "# Run face enhancement\n",
    "\n",
    "faces_upscaled_video_path = upscale_faces_cached(input_path, input_video_path)\n",
    "\n",
    "print(\"face-enhanced video available at:\", faces_upscaled_video_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fae3cb9-3693-4523-ab04-de93de41c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resizing needed: target resolution equals input resolution.\n",
      "[INFO] Running ONNX background upscaling...\n",
      "No resizing needed: target resolution equals input resolution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-11-27 04:43:03.638902769 [W:onnxruntime:, transformer_memcpy.cc:111 ApplyImpl] 2 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "\u001b[0;93m2025-11-27 04:43:03.640327412 [W:onnxruntime:, session_state.cc:1316 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2025-11-27 04:43:03.640350589 [W:onnxruntime:, session_state.cc:1318 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "Writing:   0%|          | 0/1501 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Upscaling 1501 frames with up to 8 in flightâ€¦,  scale is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitting:   0%|          | 0/1501 [00:00<?, ?it/s]\u001b[A\n",
      "Submitting:  22%|â–ˆâ–ˆâ–       | 329/1501 [00:00<00:00, 2622.06it/s]\u001b[A\n",
      "Submitting:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 592/1501 [00:01<00:01, 508.91it/s] \u001b[A\n",
      "Submitting:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 718/1501 [00:03<00:04, 174.62it/s]\u001b[A\n",
      "Submitting:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 790/1501 [00:03<00:03, 192.11it/s]\u001b[A\n",
      "Submitting:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 948/1501 [00:03<00:01, 279.47it/s]\u001b[A\n",
      "Submitting:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1038/1501 [00:03<00:01, 241.07it/s]\u001b[A\n",
      "Submitting:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1103/1501 [00:03<00:01, 272.73it/s]\u001b[A\n",
      "Submitting:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1167/1501 [00:04<00:01, 196.86it/s]\u001b[A\n",
      "Submitting:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1247/1501 [00:04<00:01, 245.21it/s]\u001b[A\n",
      "Submitting:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1337/1501 [00:04<00:00, 315.07it/s]\u001b[A\n",
      "Submitting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1501/1501 [00:04<00:00, 300.95it/s]\u001b[A\n",
      "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1501/1501 [01:38<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ffmpeg repair passthrough complete: output_videos_latest/final_without_post_process/background_upscale__b3873b888ea0/background_upscale.mp4\n",
      "Done â†’ output_videos_latest/final_without_post_process/background_upscale__b3873b888ea0/background_upscale.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Resizing video: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1501/1501 [00:02<00:00, 628.64frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ffmpeg repair passthrough complete: output_videos_latest/final_without_post_process/background_upscale__b3873b888ea0/background_upscale.mp4\n",
      "Resized video saved and replaced original at output_videos_latest/final_without_post_process/background_upscale__b3873b888ea0/background_upscale.mp4\n",
      "onnx Upscaled video at: output_videos_latest/final_without_post_process/background_upscale__b3873b888ea0/background_upscale.mp4\n"
     ]
    }
   ],
   "source": [
    "upscale_flag =True\n",
    "if upscale_flag:\n",
    "    import torch, gc\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    from Utils.main_utils import background_upscale_video_onnx_cached, downscale_video_in_place\n",
    "    \n",
    "    #input_path = faces_upscaled_video_path or restored_video_path or input_video_path\n",
    "    input_path = \"output_videos_latest/cropped_MoogaManasuluSongs-NaaPaataNeeNo_20251108174136_f531470b/final_without_post_process__0432197964f9/final_without_post_process.mp4\"\n",
    "    input_video_path = input_path\n",
    "    model = 'models/Real-ESRGAN-General-x4v3.onnx'  # âœ… Your custom model path\n",
    "    downscale_video_in_place(input_path)\n",
    "    onnx_upscaled_video = background_upscale_video_onnx_cached(input_path, input_video_path, scale = 4, model_path=model, clahe_flag=False)\n",
    "    print(\"onnx Upscaled video at:\", onnx_upscaled_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff0c3a6-7484-4371-9182-984a27e0bb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CACHE] Scene-split video found: output_videos_latest/Marilyn_Monroe_test/scene_split__3fa7c19171c5/background_upscale_images/background_upscale_bw.mp4\n",
      "Scene refs video available at: output_videos_latest/Marilyn_Monroe_test/scene_split__3fa7c19171c5/background_upscale_images/background_upscale_bw.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "from Utils.main_utils import run_scene_split_cached\n",
    "\n",
    "# You can use the output of task 1 or task 3 as input_path\n",
    "input_path = onnx_upscaled_video or faces_upscaled_video_path or restored_video_path or input_video_path\n",
    "\n",
    "preview_video_path = run_scene_split_cached(input_path, input_video_path)\n",
    "print(\"Scene refs video available at:\", preview_video_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6830af1-633c-4564-88f4-e0dbac119ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch, gc\n",
    "# torch.cuda.synchronize()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# from Utils.main_utils import upscale_video_onnx_cached\n",
    "\n",
    "# input_path = preview_video_path \n",
    "# model = 'models/real_esrgan_x4plus-real-esrgan-x4plus-float.onnx'  # âœ… Your custom model path\n",
    "\n",
    "# preview_upscaled_video = upscale_video_onnx_cached(input_path, input_video_path, 4, model_path=model)\n",
    "# print(\"Scene preview Upscaled video at:\", preview_upscaled_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4934b009-a5bc-41de-8528-8f3e4ab84894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "if not unet_flag:\n",
    "    from Utils.main_utils import deoldify_cached\n",
    "    input_path = preview_video_path  or preview_upscaled_video\n",
    "    input_path = preview_upscaled_video or preview_video_path \n",
    "    deoldify_video = deoldify_cached(input_path, input_video_path)\n",
    "    print(\"deoldify colored video at:\", deoldify_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3365315-d1d7-4fe5-be1a-40bb47b83992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(preview_upscaled_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a03fccb-388c-4513-b7f1-dadd0d81d76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CACHE] Colorized output already exists: output_videos_latest/Marilyn_Monroe_test/unet_colored_refs__517e213e08ae/unet_colored_refs.mp4\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "scene_video = preview_upscaled_video or preview_video_path \n",
    "if unet_flag:\n",
    "    \n",
    "    generator_weights = \"models/best_weights_epoch_0004.weights.h5\"\n",
    "    \n",
    "    # result = subprocess.run(\n",
    "    #     [sys.executable, \"Utils/run_unet_colorization.py\", scene_video, generator_weights, input_video_path],\n",
    "    # )\n",
    "    from Utils.main_utils import run_unet_colorization_cached_subprocess\n",
    "    \n",
    "    color_video_path = run_unet_colorization_cached_subprocess(\n",
    "        input_bw_video=scene_video,\n",
    "        unet_weights=generator_weights,\n",
    "        first_path=input_video_path\n",
    "    )\n",
    "       \n",
    "    # print(result.stdout)\n",
    "    # if result.stderr:\n",
    "    #     print(\"[ERROR]\", result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b7fd082-a9fc-4ee3-a666-e6fd8606b3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running Diffusion to enhance unet output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dl_env/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7adeef6f3c54555b001a798a1fddb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7930c07d45f1447ba4cf1a28ebfd7cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dfbdcc80e9476999bdfca7541a21f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d072fee896164da0b769687736afe8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11c40a0364f40e8851d359f9ab0faa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a981819ec8848ea8c93658a9d5c565c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcb23c2f35243b4b49a23405e6405be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c62895a700641c0a93834f250975ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60266136f06349c8b0338601e5fe039e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211f4d1b5b1a46469716f1f0df1f0624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd16914bcc64d149e3c93639fbbff8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8e9e65394c4bbba36e337308f2271c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9679dea6e34163aaee518a710e5e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14da98e43b904ae8876ab6415d0d8201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet_img2img.StableDiffusionControlNetImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/opt/conda/envs/dl_env/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/dl_env/lib/python3.11/site-packages/peft/tuners/lora/model.py:419: UserWarning: Adapter cannot be set when the model is merged. Unmerging the model first.\n",
      "  warnings.warn(\"Adapter cannot be set when the model is merged. Unmerging the model first.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load took 7.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|          | 0/18 [00:00<?, ?frame/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24e4b3270c34949b793a60a66719b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   6%|â–Œ         | 1/18 [00:01<00:31,  1.85s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790297391f5346bf8814abe7ae7ddb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  11%|â–ˆ         | 2/18 [00:03<00:24,  1.50s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18feedaa8abe404fa6b3541cefb4b38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  17%|â–ˆâ–‹        | 3/18 [00:04<00:20,  1.39s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb3913c028040afaba683ed2ab04732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:18,  1.34s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b7014e55554f5ea3bdd187af0b79f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:17,  1.31s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcdfaa7a6ed40a49481bc0c9cb42fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:15,  1.29s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba93e90b1fe428584042aed08871035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:09<00:14,  1.28s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ee5571693a4c348601cbd31eadae3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:10<00:12,  1.28s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b5ef671adf48beaf51cfa031b209f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.27s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61047e700f447c987e33805e598ebef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:13<00:10,  1.27s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0398aa13a041f1848cedeb7c33d53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:14<00:08,  1.26s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753125b92e8c46728421fd968ae9cb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:15<00:07,  1.26s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ace31e5171344428f74fd091e04f198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:16<00:06,  1.26s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2007da3842f4d0bb143d5aae933f215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:18<00:05,  1.26s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c204debcd9b642a0bd3293f8ad8a3bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:19<00:03,  1.26s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e9745f8728468d869d8543834adc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:20<00:02,  1.26s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f821d65fed4ebe9fe2a90f43d501ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:21<00:01,  1.26s/frame]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e5ec6b06f248c793885abb11ed36da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:23<00:00,  1.29s/frame]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing complete.\n",
      "diffusion_unet_enhance took 31.04s\n",
      "Diffusion enhanced video available at: output_videos_latest/Marilyn_Monroe_test/unet_enhanced__0fa0b18f8a15/unet_enhanced.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "from Utils.main_utils import enhance_unet_cached\n",
    "\n",
    "# You can use the output of task 1 or task 3 as input_path\n",
    "input_path = color_video_path\n",
    "\n",
    "color_video_path = enhance_unet_cached(input_path, input_video_path)\n",
    "print(\"Diffusion enhanced video available at:\", color_video_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131419b-c21a-443f-a2b0-77c626a9b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567b5a34-6270-4849-9480-5375f6f38751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950b66a-5346-449f-8529-da13cdc7a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Utils.main_utils import resize_video_in_place\n",
    "import os\n",
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "#scene_video = preview_video_path  or preview_upscaled_video\n",
    "dir_name = os.path.dirname(scene_video)\n",
    "# if unet_flag:\n",
    "#     color_video_path = os.path.join(dir_name, \"color.mp4\")\n",
    "# else:\n",
    "#     color_video_path = os.path.join(dir_name, \"color_deoldify.mp4\")\n",
    "resize_video_in_place(color_video_path, input_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "086d1b1d-e4b7-459d-b4aa-ca0c37f06a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/workspace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41eb8b25-100c-498e-a1a5-cc6ddb78b382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running Color propagation...\n",
      "ðŸš€ Running on GPU [0]\n",
      "/workspace\n",
      "replace all deconv with [nearest + conv]\n",
      "replace all batchnorm with instancenorm\n",
      "âœ… All models loaded from:\n",
      "   VGG19        â†’ /workspace/data/vgg19_conv.pth\n",
      "   NonlocalNet  â†’ /workspace/checkpoints/video_moredata_l1/nonlocal_net_iter_76000.pth\n",
      "   ColorVidNet  â†’ /workspace/checkpoints/video_moredata_l1/colornet_iter_76000.pth\n",
      "\n",
      "ðŸŽ¨ Starting colorization of 7 scenes...\n",
      "\n",
      "[CACHE] Skipping colorization for: background_upscale-Scene-001.mp4\n",
      "[CACHE] Skipping colorization for: background_upscale-Scene-002.mp4\n",
      "[CACHE] Skipping colorization for: background_upscale-Scene-003.mp4\n",
      "[CACHE] Skipping colorization for: background_upscale-Scene-004.mp4\n",
      "[CACHE] Skipping colorization for: background_upscale-Scene-005.mp4\n",
      "[CACHE] Skipping colorization for: background_upscale-Scene-006.mp4\n",
      "[CACHE] Skipping colorization for: background_upscale-Scene-007.mp4\n",
      "\n",
      "ðŸŽžï¸ Starting per-scene blending...\n",
      "\n",
      "[CACHE] Skipping blending for: background_upscale-Scene-001\n",
      "[CACHE] Skipping blending for: background_upscale-Scene-002\n",
      "[CACHE] Skipping blending for: background_upscale-Scene-003\n",
      "[CACHE] Skipping blending for: background_upscale-Scene-004\n",
      "ðŸ”€ Blending Scene 5: background_upscale-Scene-005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Blending background_upscale-Scene-005: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”€ Blending Scene 6: background_upscale-Scene-006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Blending background_upscale-Scene-006: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:08<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”€ Blending Scene 7: background_upscale-Scene-007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Blending background_upscale-Scene-007: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:10<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ Combining 7 blended scenes...\n",
      "\n",
      "[INFO] ffmpeg repair passthrough complete: output_videos_latest/Marilyn_Monroe_test/colored_full_video__0fa0b18f8a15/colored_full_video.mp4\n",
      "âœ… Final blended video saved to: output_videos_latest/Marilyn_Monroe_test/colored_full_video__0fa0b18f8a15/colored_full_video.mp4\n",
      "colorised final video at: output_videos_latest/Marilyn_Monroe_test/colored_full_video__0fa0b18f8a15/colored_full_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "from Utils.main_utils import colorize_scenes_cached\n",
    "\n",
    "input_path = color_video_path\n",
    "\n",
    "colorized_final_video = colorize_scenes_cached(preview_video_path,  onnx_upscaled_video , color_video_path, input_video_path)\n",
    "print(\"colorised final video at:\", colorized_final_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4176c7f0-639a-493b-bceb-749fed508ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "774c9f60-6c74-48b9-b8b3-6ad6beb68c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CACHE] postprocessed file found: output_videos_latest/Marilyn_Monroe_test/postprocess__21b520a73121/postprocess.mp4\n",
      "postprocess video at: output_videos_latest/Marilyn_Monroe_test/postprocess__21b520a73121/postprocess.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "from Utils.main_utils import postprocess_videos_cached\n",
    "\n",
    "input_path = colorized_final_video\n",
    "\n",
    "postprocess_video = postprocess_videos_cached(input_path, input_video_path)\n",
    "print(\"postprocess video at:\", postprocess_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbdff3f9-ce7a-4e1e-bee1-37ca5c27ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running Audio Remix\n",
      "[INFO] ffmpeg repair passthrough complete: output_videos_latest/Marilyn_Monroe_test/final_post_processed__574cbc07ecdd/final_post_processed.mp4\n",
      "[INFO] Audio remixed: output_videos_latest/Marilyn_Monroe_test/final_post_processed__574cbc07ecdd/final_post_processed.mp4\n",
      "[DONE] Audio Remix created at: output_videos_latest/Marilyn_Monroe_test/final_post_processed__574cbc07ecdd/final_post_processed.mp4\n",
      "final video at: output_videos_latest/Marilyn_Monroe_test/final_post_processed__574cbc07ecdd/final_post_processed.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "from Utils.main_utils import remix_audio_cached\n",
    "\n",
    "final_video = remix_audio_cached(postprocess_video, input_video_path, \"final_post_processed\")\n",
    "print(\"final video at:\", final_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c0094-226d-42d5-8803-c856d6cbf5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c549abd-01cc-431e-96a1-dd19d34fae0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217745de-7c5f-44cb-9091-560021d70c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
